# 勾配降下法
- 勾配降下法
- 確率的勾配降下法
- ミニバッチ勾配降下法
NNを学習させる手法のこと。
学習を通じて、重み・バイアスを最適化する。
誤差関数を最小にする重み・バイアスを見つけていく。

## 勾配降下法

![gif latex-81](https://user-images.githubusercontent.com/85814165/139636911-3b776db4-b84b-4ca3-b7c3-cfed8bfdeac5.gif)

ε＝学習率

学習率が大きいと、発散する可能性がある。
学習率が小さいと、収束するまでに時間がかかってしまう。また、底が複数ある場合は、１つ目の底で収束してしまう可能性がある。（極小値をとってしまう）
適切な学習率を設定しないといけない。

## アルゴリズム
- Momentum
- AdaGrad
- Adadelta
- Adam（最も使われる）

## エポック
学習する回数 epoch

#  確認テスト

Q.該当するソースコードを探してみよう(勾配降下法）

![スクリーンショット 2021-11-01 16 43 35](https://user-images.githubusercontent.com/85814165/139638312-da81fea1-0afd-4219-98b8-b995f8de68c8.png)

