# LSTM

RNNの課題→時系列を遡れば遡るほど、勾配が消失する→長い時系列の学習が困難

解決策→勾配消失の構造自体を変えて解決したものがLSTM

![スクリーンショット 2021-11-28 18 37 34](https://user-images.githubusercontent.com/85814165/143762850-b9829614-8d77-42aa-93b0-13578a997853.png)

## CEC
CECは記録機能しかない。

勾配消失および勾配爆発の解決方法として、勾配が1であれば解決できる

![gif latex-6](https://user-images.githubusercontent.com/85814165/143763035-e2d093e5-23a4-414e-94d7-d9ed04c1593c.gif)

![gif latex-7](https://user-images.githubusercontent.com/85814165/143763114-fa72b6a3-f765-4aec-af25-9ee0b5ce7e7d.gif)

## CECの課題
入力データについて時間依存度に関係なく重みが一律である。

→ニューラルネットワークの学習特性が無い。

そのため、CECの周りに学習機能を配置。

## 入力ゲートと出力ゲート

入力・出力ゲートを追加することでそれぞれのゲートへの入力値の重みを、重み行列W、Uで可変可能。

### 入力ゲート

CECへ記録させる要素

今回の入力値と前回の出力値を元にする。

### 出力ゲート

CECへどのように記録を使わせるか

今回の入力値と前回の出力値を元にする。

## 忘却ゲート

CECは過去の情報全てが保管されている。

→課題：過去の情報が不要となった場合に削除することができず、保管し続ける。

→解決策；過去の情夫が不要になった場合、そのタイミングで情報を忘却する機能が必要。

## 覗き穴結合

課題：CECの保存されている過去の情報を、任意のタイミングで他のノードに伝搬させたり、あるいは任意のタイミングで忘却させたい。CEC自身はゲート制御に影響を与えていない。

→CEC自身の値に、重み行列を介して伝搬可能にした構造

# 確認テスト

Q.シグモイド関数を微分した時、入力値が0の時に最大値をとる。その値として正しいものを選べ。

A.0.25

Q.以下の文章をLSTMに入力し空欄に当てはまる単語を予測したいとする。文中の「とても」という言葉は空欄の予測においてなくなっても影響を及ぼさないと考えられる。このような場合、どのゲートが作用とすると考えられるか。

A.忘却ゲート

# 演習チャレンジ

![スクリーンショット 2021-11-28 16 03 27](https://user-images.githubusercontent.com/85814165/143733006-75e8de95-ae47-4a02-b694-13e3c17a9b0a.png)

A.1 gradient*rate

![スクリーンショット 2021-11-28 19 11 41](https://user-images.githubusercontent.com/85814165/143763780-0f0b732f-5f8f-4cb0-9f37-360fb74c2c99.png)

A.3 input_gate*a + forget_gate*c
