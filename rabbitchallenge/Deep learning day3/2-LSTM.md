# LSTM

RNNの課題→時系列を遡れば遡るほど、勾配が消失する→長い時系列の学習が困難

解決策→勾配消失の構造自体を変えて解決したものがLSTM

![スクリーンショット 2021-11-28 18 37 34](https://user-images.githubusercontent.com/85814165/143762850-b9829614-8d77-42aa-93b0-13578a997853.png)

## CEC
CECは記録機能しかない。

勾配消失および勾配爆発の解決方法として、勾配が1であれば解決できる

![gif latex-6](https://user-images.githubusercontent.com/85814165/143763035-e2d093e5-23a4-414e-94d7-d9ed04c1593c.gif)

![gif latex-7](https://user-images.githubusercontent.com/85814165/143763114-fa72b6a3-f765-4aec-af25-9ee0b5ce7e7d.gif)

## CECの課題
入力データについて時間依存度に関係なく重みが一律である。

→ニューラルネットワークの学習特性が無い。

そのため、CECの周りに学習機能を配置。

## 入力ゲートと出力ゲート

### 入力ゲート

CECへ記録させる要素

今回の入力値と前回の出力値を元にする。

W
CECへ記録させる要素
CECへ記録させ

### 出力ゲート

CECへどのように記録を使わせるか

## 忘却ゲート
## 覗き穴結合

# 確認テスト

Q.シグモイド関数を微分した時、入力値が0の時に最大値をとる。その値として正しいものを選べ。

A.0.25

# 演習チャレンジ

![スクリーンショット 2021-11-28 16 03 27](https://user-images.githubusercontent.com/85814165/143733006-75e8de95-ae47-4a02-b694-13e3c17a9b0a.png)

A.1 gradient*rate
