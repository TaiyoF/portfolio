# CNN 畳み込みNN

画像識別や画像処理によく用いられる処理。次元的・時間的繋がりがあればCNNで可能。

## CNNの構造図の例

入力層→畳み込み層→畳み込み層→プーリング層→畳み込み層→畳み込み層→プーリング層→全結合層→出力層（出力画像）

## LeNetの構造図

![スクリーンショット 2021-11-06 9 47 18](https://user-images.githubusercontent.com/85814165/140592154-6d14a787-18b0-4a13-838d-4ec3db482eeb.png)

最終的に10種類の出力をする

(32,32)の1,024個のデータを入力

Convolutions=畳み込み演算により、(28,28,6)の4,704個のデータにする。複数層作る。

(14,14,6)の1,176個のデータにする。元々のデータの解像度をまとめる（荒くする）

(10,10,16)の1,600個のデータにする。データをまとめ、さらに複数層作る。

(5,5,16)の400個のデータにする。データをまとめる。

(120,)の120個のデータにする。複数層を1層にする。

(84,)の84個のデータにする。

(10,)10個の数字を出力する。

## 畳み込み層
畳み込み層では、画像の場合、縦・横・チャネル数の3次元のデータをそのまま学習し、次に伝えることができる。

3次元の空間情報も学習できるような層が畳み込み層。

## 畳み込みの演算概念

入力画像をフィルター（重み）を通して数値変換し、バイアスを加えて、出力させる。

4x4の画像を3x3のフィルターにかけると2x2の出力になる。

4x4の画像を2x2のフィルターにかけると3x3の出力になる。

## padding

フィルタをかけるまえに、入力画像に1~ピクセルずつ上下方向に加える。その後、畳み込みを行う。

## ストライド

これまではフィルタが1マスずつ移動していたが（ストライド1）、ストライドを使うことでストライド分ずれて畳み込み計算が可能。

## チャンネル

チャンネルはフィルタの数を示す。

# プーリング層
MaxPooling,AvgPooling(averagePooling)

プーリング層は重みがない。

対象領域のMax値もしくは平均値を取得する。


## 全結合で画像を学習した場合の課題

全結合層のデメリット：画像の場合、縦・横・チャンネルの3次元データだが、1次元のデータとして処理される。

→RGBの各チャンネル間の関連性が学習に反映されない。

# 確認テスト

Q.サイズ6x6の入力画像をサイズ2x2のフィルタで畳み込んだ時の出力画像のサイズを答えよ。なおストライドとパディングは1とする。

A.6x6の出力サイズ

Q.サイズ5x5の入力画像を、サイズ3x3のフィルタで畳み込んだ時にの出力画像サイズを答えよ。なお、ストライドは2,パディングは1とする。

A.3x3の出力サイズ

# 実装
2-6


