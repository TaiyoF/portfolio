# CNN 畳み込みNN
画像識別や画像処理によく用いられる処理。次元的・時間的繋がりがあればCNNで可能。

## CNNの構造図の例

入力層→畳み込み層→畳み込み層→プーリング層→畳み込み層→畳み込み層→プーリング層→全結合層→出力層（出力画像）

## LeNetの構造図

![スクリーンショット 2021-11-06 9 47 18](https://user-images.githubusercontent.com/85814165/140592154-6d14a787-18b0-4a13-838d-4ec3db482eeb.png)

最終的に10種類の出力をする

(32,32)の1,024個のデータを入力
Convolutions=畳み込み演算により、(28,28,6)の4,704個のデータにする。複数層作る。
(14,14,6)の1,176個のデータにする。元々のデータの解像度をまとめる（荒くする）
(10,10,16)の1,600個のデータにする。データをまとめ、さらに複数層作る。
(5,5,16)の400個のデータにする。データをまとめる。
(120,)の120個のデータにする。複数層を1層にする。
(84,)の84個のデータにする。
(10,)10個の数字を出力する。

## 畳み込み層
畳み込み層では、画像の場合、縦・横・チャネル数の3次元のデータをそのまま学習し、次に伝えることができる。
3次元の空間情報も学習できるような層が畳み込み層。

# 確認テスト

Q.サイズ6x6の入力画像をサイズ2x2のフィルタで畳み込んだ時の出力画像のサイズを答えよ。なおストライドとパディングは1とする。
