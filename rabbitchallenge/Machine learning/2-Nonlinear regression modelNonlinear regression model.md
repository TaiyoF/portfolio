# 非線形回帰モデル

## 基底展開法
よく使われる基底関数は
- 多項式関数
- ガウス型基底関数
- スプライン関数/Bスプライン関数

回帰関数として、基底関数と呼ばれる既知の非線形関数とパラメータベクトルの線形結合を使用する。

![gif latex-41](https://user-images.githubusercontent.com/85814165/138572727-4c417808-1e68-44c7-b503-53f2091efe56.gif)

- 多項式
- ガウス型基底
![gif latex-42](https://user-images.githubusercontent.com/85814165/138573065-1f52554a-4d54-4f65-8fc2-7fed8f71f5dd.gif)

## 未学習と過学習
未学習とは学習データに対して小さな誤差が得られないモデル。モデルの学習が悪いため、モデルの表現力が低い。アンダーフィットして、フィットが足りていない。
過学習とは小さな誤差が得られたが、テスト集合誤差との差が大きいモデル。表現力が高すぎる。オーバーフィットしすぎている。
- 対策1 学習データの数を増やす
- 対策2 不要な基底関数（変数）を削除して表現力を抑止
- 対策3 正規化法を用いて表現力を抑止

## 正則化法
L2ノルム→Ridge推定量（縮小推定）
L1ノルム→Lasso推定量（スパース推定）

MSEを最小にする点、MSE最小の場合オーバーフィットの可能性があり。
ではなく、パラメーターにある制約をあたえて、その中でMSEを最小にする点を見つける。

Lasso推定量は、いくつかのパラメータを正確に0に推定する。
不要な基底や変数を削除できる。変数を選択する指標となる。

## 正則化パラメータの役割
- 小さくすると制約面が大きく
- 大きくすると制約面が小さくなる

## 適切なモデル選択
交差検証法にて決定。

- ホールドアウト法
有限のデータを学習用とテスト用の2つに分割し、予測精度や誤り率を推定するために使用
課題、学習用データの割合を増やすとテスト用が減り性能評価の精度が悪くなる、テスト用のデータの割合を増やすと学習用データが減り、学習そのものの精度が落ちる。

- クロスバリデーション（交差検証）
データを仮に５分割し、イテレータ毎にモデルを作成し、そのモデル毎に検証が可能。
精度の平均を取る＝CV値
CV値が最も小さいものを採用





