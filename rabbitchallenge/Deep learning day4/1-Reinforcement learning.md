# 強化学習

# 1-1　強化学習とは

教師あり学習・教師なし学習・強化学習の分類のうちの一つ

強化学習とは、長期的に報酬を最大化できるように環境の中で行動を選択できるエージェントを作ることを目標とする機械学習の一分野

→行動の結果として与えられる利益（報酬）をもとに、行動を決定する原理を改善していく仕組み。

エージェントは、より多くの報酬を得るための方策を考える。環境の状態は変移していく。

![スクリーンショット 2021-12-03 13 40 38](https://user-images.githubusercontent.com/85814165/144546362-97afea16-2e32-4da8-9d94-d96d6056d734.png)


# 1-2 強化学習の応用例

マーケティングの場合

環境：会社の販売促進部

エージェント：プロフィールと購入履歴に基づいて、キャンペーンメールを送る顧客を決めるソフトウェア

行動：顧客ごとに送信する・しないという行動を選ぶ

報酬：キャンペーンのコストという負の報酬とキャンペーンで生み出されると推測される売上という正の報酬を受ける
 
# 1-3 探索と利用のトレードオフ

環境について事前に完璧な知識があれば、最適な行動を予測し決定することが可能。
  
→どのような顧客にキャンペーンメールを送信すると、どのような行動を行うのかが既知である状況

強化学習の場合、上記の仮定は成り立たないとして、不完全な知識をもとに行動しながら、データを収集し、最適な行動を見つけていく。

過去のデータで、ベストとされる行動のみを常に取り続ければ、他にもっといい行動を見つけることはできない。

→探索が足りない状態

⇅トレードオフの関係

未知の行動のみを常に取り続ければ、過去の経験が活かせない。

→利用が足りない状態

# 1-4 強化学習のイメージ

![スクリーンショット 2021-12-03 14 05 36](https://user-images.githubusercontent.com/85814165/144548480-db1913e9-a9eb-49f9-95f5-ba5d79c37674.png)

# 1-5 強化学習の差分

強化学習とこれまでの教師あり学習・教師なし学習の違いは、目的が異なる点です。

教師あり、なし学習では、データに含まれるパターンを見つけ出すことやそのデータから予測することが目的

強化学習は、優れた方策を見つけることが目的

## 強化学習の歴史

強化学習は、計算速度の進歩により大規模な強化学習を可能としつつある。

関数近似法とQ学習を組み合わせる手法の登場

Q学習とは、行動価値関数を行動するごとに更新することにより学習を進める方法

関数近似法とは、価値関数や方策関数を関数近似する手法

# 1-6 行動価値関数

価値関数とは、状態価値関数と行動価値関数の２種類がある。

ある状態の価値に注目する場合は、状態価値観数。

状態と価値を組み合わせた価値に注目する場合は、行動価値関数。

最近では、行動価値関数を利用される。

# 1-7 方策関数

方策関数とは、方策ベースの強化学習手法において、ある状態でどのような行動をとるのかの確率を与える関数のこと。

方策関数：π(s) = a

関数の関係：エージェントは方策に基づいて行動する、

π(s, a)；VやQをもとにどういう行動をするか→経験を活かすorチャレンジする→その瞬間、その瞬間の行動をどうするか。

V(s)；状態関数

Q(s, a)；状態＋行動関数

→ゴールまでの今の方策を続けた時の報酬の予測値が得られる。→やり続けると最終的にどうなるか。

# 1-8 方策勾配法

方策反復法（方策をモデル化して最適化する手法）

→方策勾配法

![gif latex-8](https://user-images.githubusercontent.com/85814165/144551653-607a6d02-43fc-4c4a-984d-a321fda39c73.gif)

Jは方策の良さ（定義する必要がある）

θはNNの重み相当で方策関数のパラメータ、tは時間。

NNでは誤差を小さくするが、強化学習では機体収益を最大化する。


## ![gif latex-9](https://user-images.githubusercontent.com/85814165/144552336-2bc32784-5931-4eb6-973b-6bf9f45fe375.gif)の定義方法

定義方法


